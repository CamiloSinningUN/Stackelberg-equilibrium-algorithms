{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stackleberg equilibrium\n",
    "\n",
    "This notebook is used to find the stackleberg equilibrium for a game in extensive form translated into sequence-form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplpy import AMPL\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_preprocessing(players, sequences, nodes, F, f, utilities):\n",
    "    sequences_encoded = {player: [i for i in range(len(sequences[player]))] for player in players}\n",
    "    nodes_encoded = {player: [i for i in range(len(nodes[player]))] for player in players}\n",
    "    \n",
    "    utilities_df = {player: pd.DataFrame(utilities[player], index=sequences_encoded['leader'], columns=sequences_encoded['follower']) for player in players}\n",
    "    \n",
    "    F_df = {player: pd.DataFrame(F[player], index=nodes_encoded[player], columns=sequences_encoded[player]) for player in players}\n",
    "    f_df = {player: pd.DataFrame(f[player], index=nodes_encoded[player]) for player in players}\n",
    "    M = {player: max(utilities_df[player]) - min(utilities_df[player])  for player in players}\n",
    "    \n",
    "    return utilities_df, sequences_encoded, nodes_encoded, F_df, f_df, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players, Q, H, F, f, U\n",
    "def stackleberg_equilibrium(players, sequences, nodes, F, f, utilities):\n",
    "    utilities_df, sequences_encoded, nodes_encoded, F_df, f_df, M = data_preprocessing(players, sequences, nodes, F, f, utilities)\n",
    "    \n",
    "    ampl = AMPL()\n",
    "    ampl.read('sequence_stackleberg.mod')\n",
    "    \n",
    "    ampl.set['Ql'] = sequences_encoded['leader']\n",
    "    ampl.set['Qf'] = sequences_encoded['follower']\n",
    "    \n",
    "    ampl.set['Hl'] = nodes_encoded['leader']\n",
    "    ampl.set['Hf'] = nodes_encoded['follower']\n",
    "    \n",
    "    ampl.param['Fl'] = F_df['leader']\n",
    "    ampl.param['Ff'] = F_df['follower']\n",
    "    \n",
    "    ampl.param['fl'] = f_df['leader']\n",
    "    ampl.param['ff'] = f_df['follower']\n",
    "    \n",
    "    # ampl.param['Ml'] = M['leader']\n",
    "    ampl.param['Ml'] = 10000\n",
    "    # ampl.param['Mf'] = M['follower']\n",
    "    ampl.param['Mf'] = 10000\n",
    "    \n",
    "    ampl.param['Ul'] = utilities_df['leader']\n",
    "    ampl.param['Uf'] = utilities_df['follower']\n",
    "\n",
    "    ampl.solve(solver='gurobi')\n",
    "    assert ampl.solve_result == \"solved\"\n",
    "    \n",
    "    obj = ampl.getObjective('obj').value()\n",
    "    rl = ampl.getVariable('rl').getValues().toPandas()\n",
    "    rf = ampl.getVariable('rf').getValues().toPandas()\n",
    "    z = ampl.getVariable('z').getValues().toPandas()\n",
    "\n",
    "    ampl.close()\n",
    "    \n",
    "    return obj, rl, rf, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0  0  0  0\n",
      "1  4  0  0\n",
      "2  0  0  0\n",
      "3  0  6  0\n",
      "4  0  9  0\n",
      "5  0  0  2\n",
      "6  0  0  4\n",
      "0  0  0  0\n",
      "1  4  0  0\n",
      "2  0  0  0\n",
      "3  0  1  0\n",
      "4  0  3  0\n",
      "5  0  0  1\n",
      "6  0  0  2\n",
      "   0  1  2\n",
      "0  0  0  0\n",
      "1  4  0  0\n",
      "2  0  0  0\n",
      "3  0  6  0\n",
      "4  0  9  0\n",
      "5  0  0  2\n",
      "6  0  0  4\n",
      "0  0  0  0\n",
      "1  4  0  0\n",
      "2  0  0  0\n",
      "3  0  1  0\n",
      "4  0  3  0\n",
      "5  0  0  1\n",
      "6  0  0  2\n",
      "0  0  0  0\n",
      "1  4  0  0\n",
      "2  0  0  0\n",
      "3  0  6  0\n",
      "4  0  9  0\n",
      "5  0  0  2\n",
      "6  0  0  4\n",
      "0  0  0  0\n",
      "1  4  0  0\n",
      "2  0  0  0\n",
      "3  0  1  0\n",
      "4  0  3  0\n",
      "5  0  0  1\n",
      "6  0  0  2\n",
      "Gurobi 9.5.1: optimal solution; objective 9\n",
      "6 simplex iterations\n",
      "1 branch-and-cut nodes\n",
      "plus 11 simplex iterations for intbasis\n",
      "\n",
      "RESULTS:\n",
      "Optimal strategy for follower:\n",
      "q0 -> 1\n",
      "l1 -> 1\n",
      "r1 -> 0\n",
      "Optimal strategy for leader: \n",
      "q0 -> 1\n",
      "L1 -> 0\n",
      "R1 -> 1\n",
      "R1L2 -> 0\n",
      "R1R2 -> 1\n",
      "R1L3 -> 0\n",
      "R1R3 -> 1\n",
      "Optimal objective value:  9.0\n"
     ]
    }
   ],
   "source": [
    "# Game\n",
    "players = ['leader', 'follower']\n",
    "\n",
    "# Nodes\n",
    "H_leader = ['h0', '1.1', '1.2', '1.3']\n",
    "H_follower = ['h0', '2.1']\n",
    "\n",
    "H = {'leader': H_leader, 'follower': H_follower}\n",
    "\n",
    "# Sequences\n",
    "Q_leader = ['q0', 'L1', 'R1', 'R1L2', 'R1R2', 'R1L3', 'R1R3']\n",
    "Q_follower = ['q0', 'l1', 'r1']\n",
    "\n",
    "Q = {'leader': Q_leader, 'follower': Q_follower}\n",
    "\n",
    "# F\n",
    "F_leader = [[1,0,0,0,0,0,0],\n",
    "            [-1,1,1,0,0,0,0],\n",
    "            [0,0,-1,1,1,0,0],\n",
    "            [0,0,-1,0,0,1,1]]\n",
    "\n",
    "F_follower = [[1,0,0],\n",
    "            [-1,1,1]]\n",
    "\n",
    "F = {'leader': F_leader, 'follower': F_follower}\n",
    "\n",
    "# f\n",
    "f_leader = [1, 0, 0, 0]\n",
    "\n",
    "f_follower = [1, 0]\n",
    "\n",
    "f = {'leader': f_leader, 'follower': f_follower}\n",
    "\n",
    "# utilities\n",
    "U_leader = [[0, 0, 0],\n",
    "            [4, 0, 0],\n",
    "            [0, 0, 0],\n",
    "            [0, 6, 0],\n",
    "            [0, 9, 0],\n",
    "            [0, 0, 2],\n",
    "            [0, 0, 4]]\n",
    "\n",
    "U_follower = [[0, 0, 0],\n",
    "            [4, 0, 0],\n",
    "            [0, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 3, 0],\n",
    "            [0, 0, 1],\n",
    "            [0, 0, 2]]\n",
    "\n",
    "U = {'leader': U_leader, 'follower': U_follower}\n",
    "\n",
    "obj, rl, rf, z = stackleberg_equilibrium(players, Q, H, F, f, U)\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "print(\"Optimal strategy for follower:\")\n",
    "for index, qf in rf.iterrows():\n",
    "    print(Q['follower'][index], \"->\", qf['rf.val'])\n",
    "print(\"Optimal strategy for leader: \")\n",
    "for index, ql in rl.iterrows():\n",
    "    print(Q['leader'][index], \"->\", ql['rl.val'])\n",
    "print(\"Optimal objective value: \", obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4\n",
      "0  0  0.0  0.0  0.0  0.0\n",
      "1  0  1.0  0.5  0.5  0.5\n",
      "2  0  0.5  1.0  0.5  0.5\n",
      "3  0  0.5  0.5  1.0  0.5\n",
      "4  0  0.5  0.5  0.5  1.0\n",
      "0  0  0.0  0.0  0.0  0.0\n",
      "1  0  0.0  0.4  0.3  0.3\n",
      "2  0  0.6  0.0  0.4  0.3\n",
      "3  0  0.7  0.6  0.0  0.4\n",
      "4  0  0.7  0.7  0.6  0.0\n",
      "   0    1    2    3    4\n",
      "0  0  0.0  0.0  0.0  0.0\n",
      "1  0  1.0  0.5  0.5  0.5\n",
      "2  0  0.5  1.0  0.5  0.5\n",
      "3  0  0.5  0.5  1.0  0.5\n",
      "4  0  0.5  0.5  0.5  1.0\n",
      "0  0  0.0  0.0  0.0  0.0\n",
      "1  0  0.0  0.4  0.3  0.3\n",
      "2  0  0.6  0.0  0.4  0.3\n",
      "3  0  0.7  0.6  0.0  0.4\n",
      "4  0  0.7  0.7  0.6  0.0\n",
      "0  0  0.0  0.0  0.0  0.0\n",
      "1  0  1.0  0.5  0.5  0.5\n",
      "2  0  0.5  1.0  0.5  0.5\n",
      "3  0  0.5  0.5  1.0  0.5\n",
      "4  0  0.5  0.5  0.5  1.0\n",
      "0  0  0.0  0.0  0.0  0.0\n",
      "1  0  0.0  0.4  0.3  0.3\n",
      "2  0  0.6  0.0  0.4  0.3\n",
      "3  0  0.7  0.6  0.0  0.4\n",
      "4  0  0.7  0.7  0.6  0.0\n",
      "Gurobi 9.5.1: optimal solution; objective 0.7598039216\n",
      "50 simplex iterations\n",
      "1 branch-and-cut nodes\n",
      "plus 34 simplex iterations for intbasis\n",
      "\n",
      "RESULTS:\n",
      "Optimal strategy for follower:\n",
      "q0 -> 1\n",
      "t1 -> 1\n",
      "t2 -> 0\n",
      "t3 -> 0\n",
      "t4 -> 0\n",
      "Optimal strategy for leader: \n",
      "q0 -> 1.0\n",
      "t1 -> 0.5196078431372549\n",
      "t2 -> 0.3254901960784314\n",
      "t3 -> 0.1254901960784314\n",
      "t4 -> 0.029411764705882353\n",
      "Optimal objective value:  0.7598039215686274\n"
     ]
    }
   ],
   "source": [
    "# Game\n",
    "players = ['leader', 'follower']\n",
    "\n",
    "# Nodes\n",
    "H_leader = ['h0', '1.1']\n",
    "H_follower = ['h0', '2.1']\n",
    "\n",
    "H = {'leader': H_leader, 'follower': H_follower}\n",
    "\n",
    "# Sequences\n",
    "Q_leader = ['q0', 't1', 't2', 't3', 't4']\n",
    "Q_follower = ['q0', 't1', 't2', 't3', 't4']\n",
    "\n",
    "Q = {'leader': Q_leader, 'follower': Q_follower}\n",
    "\n",
    "# F\n",
    "F_leader = [[1,0,0,0,0],\n",
    "            [-1,1,1,1,1]]\n",
    "\n",
    "F_follower = [[1,0,0,0,0],\n",
    "            [-1,1,1,1,1]]\n",
    "\n",
    "F = {'leader': F_leader, 'follower': F_follower}\n",
    "\n",
    "# f\n",
    "f_leader = [1, 0]\n",
    "\n",
    "f_follower = [1, 0]\n",
    "\n",
    "f = {'leader': f_leader, 'follower': f_follower}\n",
    "\n",
    "# utilities\n",
    "U_leader = [[0, 0, 0, 0, 0],\n",
    "            [0, 1, 0.5, 0.5, 0.5],\n",
    "            [0, 0.5, 1, 0.5, 0.5],\n",
    "            [0, 0.5, 0.5, 1, 0.5],\n",
    "            [0, 0.5, 0.5, 0.5, 1]]\n",
    "\n",
    "U_follower = [[0, 0, 0, 0, 0],\n",
    "            [0, 0, 0.4, 0.3, 0.3],\n",
    "            [0, 0.6, 0, 0.4, 0.3],\n",
    "            [0, 0.7, 0.6, 0, 0.4],\n",
    "            [0, 0.7, 0.7, 0.6, 0]]\n",
    "\n",
    "U = {'leader': U_leader, 'follower': U_follower}\n",
    "\n",
    "obj, rl, rf, z = stackleberg_equilibrium(players, Q, H, F, f, U)\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "print(\"Optimal strategy for follower:\")\n",
    "for index, qf in rf.iterrows():\n",
    "    print(Q['follower'][index], \"->\", qf['rf.val'])\n",
    "print(\"Optimal strategy for leader: \")\n",
    "for index, ql in rl.iterrows():\n",
    "    print(Q['leader'][index], \"->\", ql['rl.val'])\n",
    "print(\"Optimal objective value: \", obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
